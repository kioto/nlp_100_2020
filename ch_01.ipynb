{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第１章：準備体操\n",
    "\n",
    "## 00.文字列の逆順\n",
    "\n",
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR = 'stressed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接逆順にする\n",
    "STR[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# リストに代入して副作用ありメソッドreverse()を使う\n",
    "a = list(STR)\n",
    "a.reverse()\n",
    "''.join(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'desserts'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iteratorを返すreversedと内包表記\n",
    "''.join([ s for s in reversed(list(STR))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01. 「パタトクカシーー」\n",
    "\n",
    "「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．\n",
    "\n",
    "0:パ<br>\n",
    "**1:タ**<br>\n",
    "2:ト<br>\n",
    "**3:ク**<br>\n",
    "4:カ<br>\n",
    "**5:シ**<br>\n",
    "6:ー<br>\n",
    "**7:ー**<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR = u'パタトクカシーー'\n",
    "idxs = (1, 3, 5, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'タクシー'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STR[1]+STR[3]+STR[5]+STR[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "タクシー\n"
     ]
    }
   ],
   "source": [
    "# forループを使う\n",
    "buf = ''\n",
    "for i in idxs:\n",
    "    buf += STR[i]\n",
    "print(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'タクシー'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 内包表記を使う\n",
    "''.join([STR[idx] for idx in idxs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "タクシー\n"
     ]
    }
   ],
   "source": [
    "# for+enumerateを使う\n",
    "buf = ''\n",
    "for idx, s in enumerate(STR):\n",
    "        if idx in idxs:\n",
    "            buf += s\n",
    "print(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'タクシー'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 内包表記を使う\n",
    "''.join([ s for idx, s in enumerate(STR) if idx in idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "\n",
    "「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "STR1 = 'パトカー'\n",
    "STR2 = 'タクシー'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'パタトクカシーー'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 直接連結する\n",
    "STR1[0]+STR2[0]+STR1[1]+STR2[1]+STR1[2]+STR2[2]+STR1[3]+STR2[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "# forループを使う\n",
    "# ただし、STR1とSTR2の長さが同じであること\n",
    "buf = ''\n",
    "for i in range(len(STR1)):\n",
    "    buf += STR1[i] + STR2[i]\n",
    "print(buf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "# listにしてpopする方法\n",
    "str1 = list(STR1)\n",
    "str2 = list(STR2)\n",
    "buf = ''\n",
    "while str1 and str2:\n",
    "    if str1:\n",
    "        buf += str1.pop(0)\n",
    "    if str2:\n",
    "        buf += str2.pop(0)\n",
    "print(buf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. 円周率\n",
    "\n",
    "“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE = u'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Now', 'I', 'need', 'a', 'drink', 'alcoholic', 'of', 'course', 'after', 'the', 'heavy', 'lectures', 'involving', 'quantum', 'mechanics']\n"
     ]
    }
   ],
   "source": [
    "# 単語を取得する\n",
    "import re\n",
    "words = re.findall(r'[a-zA-Z]+', SENTENCE)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Now', 'I', 'need', 'a', 'drink', 'alcoholic', 'of', 'course', 'after', 'the', 'heavy', 'lectures', 'involving', 'quantum', 'mechanics']\n"
     ]
    }
   ],
   "source": [
    "# 内包表記で実行\n",
    "words = [w for w in re.findall(r'[a-zA-Z]+', SENTENCE)]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "# アルファベットの文字数のリストにする\n",
    "word_len_list = [len(w) for w in re.findall(r'[a-zA-Z]+', SENTENCE)]\n",
    "print(word_len_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 04. 元素記号\n",
    "\n",
    "“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n",
    "# 先頭１文字\n",
    "indexes = [1, 5, 6, 7, 8, 9, 15, 16, 19] \n",
    "# それ以外は先頭２文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hi', 'He', 'Lied', 'Because', 'Boron', 'Could', 'Not', 'Oxidize', 'Fluorine', 'New', 'Nations', 'Might', 'Also', 'Sign', 'Peace', 'Security', 'Clause', 'Arthur', 'King', 'Can']\n"
     ]
    }
   ],
   "source": [
    "# 単語を取り出す\n",
    "words = re.findall(r'[a-zA-Z]+', SENTENCE)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "He\n",
      "Li\n",
      "Be\n",
      "B\n",
      "C\n",
      "N\n",
      "O\n",
      "F\n",
      "Ne\n",
      "Na\n",
      "Mi\n",
      "Al\n",
      "Si\n",
      "P\n",
      "S\n",
      "Cl\n",
      "Ar\n",
      "K\n",
      "Ca\n"
     ]
    }
   ],
   "source": [
    "# for+enumerateを使って、文字列を取り出す\n",
    "for idx, word in enumerate(re.findall(r'[a-zA-Z]+', SENTENCE)):\n",
    "    if idx+1 in indexes:\n",
    "        print(word[0])  # 先頭１文字目\n",
    "    else:\n",
    "        print(word[:2])  # 先頭の２文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H\n",
      "He\n",
      "Li\n",
      "Be\n",
      "B\n",
      "C\n",
      "N\n",
      "O\n",
      "F\n",
      "Ne\n",
      "Na\n",
      "Mi\n",
      "Al\n",
      "Si\n",
      "P\n",
      "S\n",
      "Cl\n",
      "Ar\n",
      "K\n",
      "Ca\n"
     ]
    }
   ],
   "source": [
    "# for+enumerateを使って、文字列を取り出す\n",
    "# enumerateを1から開始\n",
    "for idx, word in enumerate(re.findall(r'[a-zA-Z]+', SENTENCE), start=1):\n",
    "    if idx in indexes:\n",
    "        print(word[0])   # 先頭１文字目\n",
    "    else:\n",
    "        print(word[:2])  # 先頭の２文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 'H', 2: 'He', 3: 'Li', 4: 'Be', 5: 'B', 6: 'C', 7: 'N', 8: 'O', 9: 'F', 10: 'Ne', 11: 'Na', 12: 'Mi', 13: 'Al', 14: 'Si', 15: 'P', 16: 'S', 17: 'Cl', 18: 'Ar', 19: 'K', 20: 'Ca'}\n"
     ]
    }
   ],
   "source": [
    "# 辞書型に登録\n",
    "num_to_es = {}\n",
    "for idx, word in enumerate(re.findall(r'[a-zA-Z]+', SENTENCE), start=1):\n",
    "    if idx in indexes:\n",
    "        num_to_es[idx] = word[0]   # 先頭１文字目\n",
    "    else:\n",
    "        num_to_es[idx] = word[:2]  # 先頭の２文字\n",
    "print(num_to_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([(1, 'H'), (2, 'He'), (3, 'Li'), (4, 'Be'), (5, 'B'), (6, 'C'), (7, 'N'), (8, 'O'), (9, 'F'), (10, 'Ne'), (11, 'Na'), (12, 'Mi'), (13, 'Al'), (14, 'Si'), (15, 'P'), (16, 'S'), (17, 'Cl'), (18, 'Ar'), (19, 'K'), (20, 'Ca')])\n"
     ]
    }
   ],
   "source": [
    "# OrederedDictを使った場合\n",
    "# Python 3.7でdictは順序も保証されるので、もう使われなくなる記述かも\n",
    "from collections import OrderedDict\n",
    "num_to_es = OrderedDict()\n",
    "for idx, word in enumerate(re.findall(r'[a-zA-Z]+', SENTENCE), start=1):\n",
    "    if idx in indexes:\n",
    "        num_to_es[idx] = word[0]   # 先頭１文字目\n",
    "    else:\n",
    "        num_to_es[idx] = word[:2]  # 先頭の２文字\n",
    "print(num_to_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05. n-gram\n",
    "\n",
    "与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．\n",
    "\n",
    "補足）<br>\n",
    "[Qiita : N-gramの作り方](https://qiita.com/kazmaw/items/4df328cba6429ec210fb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE = 'I am an NLPer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'a', 'm', ' ', 'a', 'n', ' ', 'N', 'L', 'P', 'e', 'r']\n",
      "['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n",
      "['I a', ' am', 'am ', 'm a', ' an', 'an ', 'n N', ' NL', 'NLP', 'LPe', 'Per']\n"
     ]
    }
   ],
   "source": [
    "# 文字n-gram\n",
    "# ベタにやった場合\n",
    "def char_ngram_1(sentence, n):\n",
    "    res = []\n",
    "    for i in range(len(sentence)-(n-1)):\n",
    "        word = sentence[i:i+n]\n",
    "        res.append(word)\n",
    "    return res\n",
    "\n",
    "print(char_ngram_1(SENTENCE, 1))\n",
    "print(char_ngram_1(SENTENCE, 2))\n",
    "print(char_ngram_1(SENTENCE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', ' ', 'a', 'm', ' ', 'a', 'n', ' ', 'N', 'L', 'P', 'e', 'r']\n",
      "['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n",
      "['I a', ' am', 'am ', 'm a', ' an', 'an ', 'n N', ' NL', 'NLP', 'LPe', 'Per']\n"
     ]
    }
   ],
   "source": [
    "# 文字n-gram\n",
    "# 内包表記を使った場合\n",
    "def char_ngram_2(sentence, n):\n",
    "    return [ sentence[i:i+n] for i in range(len(sentence) - (n-1)) ]\n",
    "\n",
    "print(char_ngram_2(SENTENCE, 1))\n",
    "print(char_ngram_2(SENTENCE, 2))\n",
    "print(char_ngram_2(SENTENCE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I'], ['am'], ['an'], ['NLPer']]\n",
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "[['I', 'am', 'an'], ['am', 'an', 'NLPer']]\n"
     ]
    }
   ],
   "source": [
    "# ベタにやる場合\n",
    "def word_ngram_1(sentence, n):\n",
    "    words = sentence.split(' ')\n",
    "    res = []\n",
    "    for i in range(len(words) - (n - 1)):\n",
    "        res.append(words[i:i+n])\n",
    "    \n",
    "    return res\n",
    "\n",
    "print(word_ngram_1(SENTENCE, 1))\n",
    "print(word_ngram_1(SENTENCE, 2))\n",
    "print(word_ngram_1(SENTENCE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I'], ['am'], ['an'], ['NLPer']]\n",
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "[['I', 'am', 'an'], ['am', 'an', 'NLPer']]\n"
     ]
    }
   ],
   "source": [
    "# 内包表記を使う場合\n",
    "def word_ngram_2(sentence, n):\n",
    "    words = sentence.split(' ')\n",
    "    return [ words[i:i+n] for i in range(len(words) - (n-1)) ]\n",
    "\n",
    "print(word_ngram_2(SENTENCE, 1))\n",
    "print(word_ngram_2(SENTENCE, 2))\n",
    "print(word_ngram_2(SENTENCE, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['I'], ['am'], ['an'], ['NLPer']]\n",
      "[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "[['I', 'am', 'an'], ['am', 'an', 'NLPer']]\n"
     ]
    }
   ],
   "source": [
    "# char_ngram_2を使う場合\n",
    "# これでも動くが、char_ngram_2の第一引数が文字列でなくリストで与えられる。\n",
    "# char_ngram_2を拡張することになり、文字列専用の処理を加えてしまうと、word_ngram_3()\n",
    "# を呼び出す時にエラーになる。このようなコーディングは避けること。\n",
    "def word_ngram_3(sentence, n):\n",
    "    return char_ngram_2(sentence.split(' '), n)\n",
    "\n",
    "print(word_ngram_3(SENTENCE, 1))\n",
    "print(word_ngram_3(SENTENCE, 2))\n",
    "print(word_ngram_3(SENTENCE, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06. 集合\n",
    "\n",
    "“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORD1 = 'paraparaparadise'\n",
    "WORD2 = 'paragraph'\n",
    "TARGET = 'se'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X = {'se', 'di', 'ra', 'is', 'ap', 'ad', 'ar', 'pa'}\n",
      "Y = {'ag', 'ph', 'ra', 'ap', 'ar', 'gr', 'pa'}\n"
     ]
    }
   ],
   "source": [
    "# 集合を求める\n",
    "X = set(char_ngram_2(WORD1, 2))\n",
    "Y = set(char_ngram_2(WORD2, 2))\n",
    "print('X =', X)\n",
    "print('Y =', Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合 X + Y = {'se', 'ag', 'ph', 'di', 'ra', 'is', 'ap', 'ad', 'ar', 'gr', 'pa'}\n",
      "積集合 X * Y = {'ar', 'ap', 'pa', 'ra'}\n",
      "差集合 X - Y = {'se', 'ad', 'di', 'is'}\n",
      "差集合 Y - X = {'ph', 'ag', 'gr'}\n"
     ]
    }
   ],
   "source": [
    "print('和集合 X + Y =', X.union(Y))\n",
    "print('積集合 X * Y =', X & Y)\n",
    "print('差集合 X - Y =', X.difference(Y))\n",
    "print('差集合 Y - X =', Y.difference(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合 X + Y = {'se', 'ag', 'ph', 'di', 'is', 'ra', 'ap', 'ad', 'ar', 'gr', 'pa'}\n",
      "積集合 X * Y = {'ar', 'ap', 'pa', 'ra'}\n",
      "差集合 X - Y = {'se', 'ad', 'di', 'is'}\n",
      "差集合 Y - X = {'ph', 'ag', 'gr'}\n"
     ]
    }
   ],
   "source": [
    "# 別解：リストに展開して処理する方法\n",
    "print('和集合 X + Y =', set(list(X) + list(Y)))\n",
    "print('積集合 X * Y =', set([w for w in X if w in Y]))\n",
    "print('差集合 X - Y =', set([w for w in X if w not in Y]))\n",
    "print('差集合 Y - X =', set([w for w in Y if w not in X]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'se' は X{'se', 'di', 'ra', 'is', 'ap', 'ad', 'ar', 'pa'} に含まれている: True\n",
      "'se' は Y{'ag', 'ph', 'ra', 'ap', 'ar', 'gr', 'pa'} に含まれている: False\n"
     ]
    }
   ],
   "source": [
    "# 'se'がXおよびYに含まれているか？\n",
    "print(\"'%s' は X%s に含まれている: %s\" % (TARGET, X, TARGET in X))\n",
    "print(\"'%s' は Y%s に含まれている: %s\" % (TARGET, Y, TARGET in Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'se' は X{'se', 'di', 'ra', 'is', 'ap', 'ad', 'ar', 'pa'} に含まれている: True\n",
      "'se' は Y{'ag', 'ph', 'ra', 'ap', 'ar', 'gr', 'pa'} に含まれている: False\n"
     ]
    }
   ],
   "source": [
    "# 別解：setに変換して部分集合、上位集合で判定する方法\n",
    "print(\"'%s' は X%s に含まれている: %s\" % (TARGET, X, X >= set([TARGET])))\n",
    "print(\"'%s' は Y%s に含まれている: %s\" % (TARGET, Y, set(TARGET) <= Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 07. テンプレートによる文生成\n",
    "\n",
    "引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.400000\n"
     ]
    }
   ],
   "source": [
    "# 引数の型が決まっている場合\n",
    "def gen_sentence_1(x, y, z):\n",
    "    return '%d時の%sは%f' % (x, y, z)\n",
    "\n",
    "print(gen_sentence_1(12, '気温', 22.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.400000\n"
     ]
    }
   ],
   "source": [
    "# 引数を文字列に変換する場合（引数の方が決まっていない場合）\n",
    "def gen_sentence_2(x, y, z):\n",
    "    return '%s時の%sは%s' % (str(x), str(y), str(z))\n",
    "\n",
    "print(gen_sentence_1(12, '気温', 22.4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.400000\n"
     ]
    }
   ],
   "source": [
    "# フォーマット済み文字列リテラルを使用する場合\n",
    "def gen_sentence_2(x, y, z):\n",
    "    return f'{x}時の{y}は{z}'\n",
    "\n",
    "print(gen_sentence_1(12, '気温', 22.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08. 暗号文\n",
    "\n",
    "与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "\n",
    "英小文字ならば(219 - 文字コード)の文字に置換\n",
    "その他の文字はそのまま出力\n",
    "この関数を用い，英語のメッセージを暗号化・復号化せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zAyBxC cXbYaZ\n",
      "aAbBcC xXyYzZ\n"
     ]
    }
   ],
   "source": [
    "# 直接書いた場合\n",
    "def cipher(sentence):\n",
    "    buf = []\n",
    "    for c in sentence:\n",
    "        if ord('a') <= ord(c) <= ord('z') :\n",
    "            buf.append(chr(219-ord(c)))\n",
    "        else:\n",
    "            buf.append(c)\n",
    "\n",
    "    return ''.join(buf)\n",
    "\n",
    "print(cipher('aAbBcC xXyYzZ'))\n",
    "print(cipher('zAyBxC cXbYaZ'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zAyBxC cXbYaZ\n",
      "aAbBcC xXyYzZ\n"
     ]
    }
   ],
   "source": [
    "# 内包表記を使った場合\n",
    "def cipher(sentence):\n",
    "    return ''.join([chr(219-ord(c)) if ord('a') <= ord(c) <= ord('z') else c \\\n",
    "                    for c in sentence])\n",
    "\n",
    "print(cipher('aAbBcC xXyYzZ'))\n",
    "print(cipher('zAyBxC cXbYaZ'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 09. Typoglycemia\n",
    "\n",
    "スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTENCE = 'I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BEFORE: \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind.\"\n",
      "AFTER : \"I phenomenal reading that I could human couldn’t what I was power : the believe actually of the understand mind.\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def gen_typoglycemia(sentence):\n",
    "    # 単語のリストに分割\n",
    "    words = sentence.split(' ')\n",
    "    # ４文字を超える単語のリスト　\n",
    "    long_words = []\n",
    "    for idx in range(len(words)):\n",
    "        if idx == 0 or idx == len(words)-1:\n",
    "            # 先頭と末尾の単語はそのままなのでスキップ　\n",
    "            continue\n",
    "\n",
    "        word = words[idx]\n",
    "        if len(word) > 4:\n",
    "            long_words.append(word)\n",
    "    \n",
    "    # ４文字を超える単語を並び替える\n",
    "    random.shuffle(long_words)\n",
    "\n",
    "    # 先頭の単語を先にセット\n",
    "    res = []    \n",
    "    res.append(words[0])\n",
    "    # ２番目の単語から、最後から２番目の単語までループ\n",
    "    for w in words[1:-1]:\n",
    "        if len(w) > 4:\n",
    "            res.append(long_words.pop(0))  # リストの先頭要素を取り出す\n",
    "        else:\n",
    "            res.append(w)\n",
    "\n",
    "    # 最後の単語をセット\n",
    "    res.append(words[-1])\n",
    "    \n",
    "    return ' '.join(res)\n",
    "\n",
    "print(f'BEFORE: \"{SENTENCE}\"')\n",
    "print(f'AFTER : \"{gen_typoglycemia(SENTENCE)}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
